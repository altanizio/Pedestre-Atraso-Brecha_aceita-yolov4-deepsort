{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "comp_atraso_YOLO_DeepSort_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmK7HIzhQ-Di"
      },
      "source": [
        "# Clicar em arquivo e salvar uma c√≥pia no Drive\n",
        "## Fonte/cr√©ditos: https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "## Github: https://github.com/altanizio/Pedestre-Atraso-Brecha_aceita-yolov4-deepsort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ieYPKgSbI4"
      },
      "source": [
        "# ‚öô Pr√©-processamento\n",
        "\n",
        "O v√≠deo de an√°lise deve estar no Google Drive e estar em .mp4.\n",
        "\n",
        "O c√≥digo abaixo seta o diret√≥rio no drive e apresenta fun√ß√µes pra converter üìº e cortar ‚úÇ o v√≠deo. \n",
        "\n",
        "Os scripts est√£o em /scripts_pre-processamento no github\n",
        "\n",
        "## Defini√ß√£o da √°rea de conflito\n",
        "\n",
        "Primeiro √© nescess√°rio executar o area_conflito.py para definir a √°rea de conflito, pois o colab n√£o permite a intera√ß√£o no output\n",
        "\n",
        "Execute o script. Escolha o V√≠deo. Clique em quatro dos veritices de interesse, comece pelo sentido de travessia dos pedestres. Aperte esc duas vezes. O √∫ltimo vetor do output √© a defini√ß√£o da √°rea de conflito.\n",
        "\n",
        "<p align=\"left\"><img src=\"https://raw.githubusercontent.com/altanizio/Pedestre-Atraso-Brecha_aceita-yolov4-deepsort/master/data/helpers/ex_cut.gif\"\\></p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YynXmiYTS2Wc"
      },
      "source": [
        "## Pastas e arquivos\n",
        "\n",
        "### Passos:\n",
        "\n",
        "Defini√ß√£o da pasta de trabalho. (rode sempre que iniciar)\n",
        "\n",
        "Clonar o diret√≥rio do github com os c√≥digos. (salve no seu drive para n√£o precisar baixar sempre)\n",
        "\n",
        "Baixar os pesos do modelo pr√©-treinado. (o mesmo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L006L2OgdBTu"
      },
      "source": [
        "import os "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhkzoqCegHTJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww0ChmWfEzLH"
      },
      "source": [
        "# Montar o drive no colab, se precisar - precisa dessa pasta YOLO no diret√≥rio raiz\n",
        "if os.path.isdir('/content/drive'):\n",
        "  %cd drive/MyDrive/YOLO\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  %cd drive/MyDrive/YOLO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTCZvbGQd01f"
      },
      "source": [
        "#if not os.path.isdir('core'):\n",
        "#  print('a')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlHeOsFC-hq0"
      },
      "source": [
        "# clone repository for deepsort with yolov4\n",
        "#The following cell will clone the yolov4-deepsort repository from github, to enable the rest of the tutorial and grab the code.\n",
        "#if not os.path.isdir('core'):\n",
        "#  !git clone https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "#  %cd yolov4-deepsort/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wULUE8Ql_BIB"
      },
      "source": [
        "# download yolov4 model weights to data folder\n",
        "#!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights -P data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pko9h69K_MVe"
      },
      "source": [
        "# Convert darknet weights to tensorflow model\n",
        "#!python save_model.py --model yolov4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho_NPdQvDHAG"
      },
      "source": [
        "##!pip install -r requirements-gpu.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuFxLckgS-9O"
      },
      "source": [
        "## Execute os scripts converter.cmd para converter os v√≠deos para uma condi√ß√£o adequada (mps, fps, etc.)\n",
        "\n",
        "## Execute cut_videos.py para cortar os trechos para a an√°lise.\n",
        "\n",
        "Obs.: edite os c√≥digos para adequar com os nomes e objetivos. √â poss√≠vel rodar os c√≥digos aqui, entretanto √© melhor rodar localmente esses scripts para melhor organiza√ß√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2iAOudPQWkx"
      },
      "source": [
        "# Cortar uma parte do v√≠deo espec√≠fica\n",
        "#from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "#ffmpeg_extract_subclip(\"./data/video/\"+ nome_arquivo_video +\".avi\", 180, 240, targetname=\"./data/video/\"+ nome_arquivo_video +\".avi\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoiYRah1J2IR"
      },
      "source": [
        "# Converter o v√≠deo para mp4 -> nescess√°rio para evitar problemas com o fps\n",
        "#%cd ./data/video/\n",
        "#!ffmpeg -y -loglevel panic -i domManuel.avi domManuel.mp4\n",
        "#%cd ..\n",
        "#%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAwao7nW02rd"
      },
      "source": [
        "# Converter o v√≠deo para mp4 -> nescess√°rio para evitar problemas com o fps\n",
        "#%cd ./data/video/\n",
        "#!ffmpeg -y -loglevel panic -i avAbolicao.avi -filter:v fps=10 avAbolicao.mp4\n",
        "#%cd ..\n",
        "#%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXCD_t6wTSxB"
      },
      "source": [
        "# Modelo de detec√ß√£o"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrl_ybzuTWs5"
      },
      "source": [
        "## Vari√°veis de entrada do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKtRTrtc_RcQ"
      },
      "source": [
        "cont_line = [[1032, 596, 1099, 403], [1099, 403, 359, 273], [359, 273, 186, 433], [186, 433, 1032, 596]]  # Ret√¢ngulo da √°rea de conflito de interesse // come√ßa pelo pedestre (primeiro dois pontos) //\n",
        "\n",
        "nome_arquivo_video = 'avUniversidade_150_180'\n",
        "\n",
        "if not os.path.exists('./outputs/'+ nome_arquivo_video):\n",
        "    os.makedirs('./outputs/'+ nome_arquivo_video)\n",
        "text_file = open('./outputs/'+ nome_arquivo_video +'/otm.txt', \"w+\")\n",
        "text_file.write(\"cont_line = %s\" % cont_line)\n",
        "text_file.close()\n",
        "\n",
        "# Fonte: https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "framework = 'tf' # tf, tflite, trt\n",
        "weights = './checkpoints/yolov4-416' # path to weights file\n",
        "size = 416 # resize images to\n",
        "tiny = False #yolo or yolo-tiny\n",
        "model = 'yolov4' # yolov3 or yolov4\n",
        "video = \"./data/video/\"+ nome_arquivo_video +\".mp4\" # path to input video \n",
        "output = './outputs/'+ nome_arquivo_video +'/tracker.avi' # path to output video\n",
        "output_format = 'XVID' # codec used in VideoWriter when saving video to file\n",
        "iou = 0.45 # iou threshold\n",
        "score = 0.5 # score threshold\n",
        "dont_show = True\n",
        "info = True # show detailed info of tracked objects\n",
        "saida = True\n",
        "\n",
        "#x_r = 20# tamanho do eixo x real em metros\n",
        "#y_r = 9.2 # tamanho do eixo y real em metros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHj6IzNkTqNQ"
      },
      "source": [
        "## Bibliotecas necess√°rias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdMjutDhNYCq"
      },
      "source": [
        "import os\n",
        "# Fonte: https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "# comment out below line to enable tensorflow logging outputs\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import time\n",
        "import tensorflow as tf\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "import core.utils as utils\n",
        "from core.yolov4 import filter_boxes\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from core.config import cfg\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "# deep sort imports\n",
        "from deep_sort import preprocessing, nn_matching\n",
        "from deep_sort.detection import Detection\n",
        "from deep_sort.tracker import Tracker\n",
        "from tools import generate_detections as gdet\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Manipula√ß√£o dos dados\n",
        "import pandas as pd\n",
        "\n",
        "# N√£o mostrar avisos\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UClyMXAcTuzp"
      },
      "source": [
        "## Fun√ß√µes para verificar travessias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqgT8FSENcMz"
      },
      "source": [
        "def centroid_box(box): #Retorna o centr√≥ide\n",
        "  return [int(abs(box[0] + box[2])/2), int(abs(box[1] + box[3])/2)]\n",
        "\n",
        "def dominio(ponto,linha): # Retorna se o ponto esta dentro da √°rea de detec√ß√£o - necess√°rio para n√£o contar pedestres ou carros que n√£o est√£o na √°rea de conflito de interesse\n",
        "    if abs(linha[1]-linha[3]) > abs(linha[0]-linha[2]):\n",
        "        if (ponto[1] - linha[1]) * (linha[3] - ponto[1]) >= -0.2:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "    else:\n",
        "        if (ponto[0] - linha[0]) * (linha[2] - ponto[0]) >= -0.2:\n",
        "            return True\n",
        "        else:\n",
        "            return False  \n",
        "\n",
        "\n",
        "def passou_da_linha(ponto,linha): # Verifica se o ponto esta acima ou abaixo de uma linha - com isso √© poss√≠vel verificar se o pedestre entrou na √°rea de conflito\n",
        "  #y = ax + b\n",
        "  #try:  \n",
        "    a = (linha[1]-linha[3])/(linha[0]-linha[2])\n",
        "    b = linha[1] - a*linha[0]\n",
        "\n",
        "    if ponto[1]<(a*ponto[0] + b):\n",
        "        return 'acima'\n",
        "    else:\n",
        "        return 'abaixo'\n",
        "  #except:\n",
        "  #      return 'error'\n",
        "\n",
        "def passou_da_linha_reta_horizontal(ponto,linha): # mesmo do anterior, mas de forma mais simples\n",
        "    if ponto[1]>linha:\n",
        "        return 'abaixo'\n",
        "    else:\n",
        "        return 'acima'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WPCuLG1TzJt"
      },
      "source": [
        "## Par√¢metros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfa_FRJJPJcK"
      },
      "source": [
        "# Fonte: https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "# Definition of the parameters\n",
        "max_cosine_distance = 0.4\n",
        "nn_budget = None\n",
        "nms_max_overlap = 1.0\n",
        "\n",
        "# initialize deep sort\n",
        "model_filename = 'model_data/mars-small128.pb'\n",
        "encoder = gdet.create_box_encoder(model_filename, batch_size=1)\n",
        "# calculate cosine distance metric\n",
        "metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
        "# initialize tracker\n",
        "tracker = Tracker(metric)\n",
        "\n",
        "# load configuration for object detector\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)\n",
        "#STRIDES, ANCHORS, NUM_CLASS, XYSCALE = utils.load_config(FLAGS)\n",
        "input_size = size\n",
        "video_path = video\n",
        "\n",
        "#conflict_area = FLAGS.conflict_area\n",
        "#print(conflict_area)\n",
        "conflict_area = cont_line\n",
        "\n",
        "# load tflite model if flag is set\n",
        "if framework == 'tflite':\n",
        "    interpreter = tf.lite.Interpreter(model_path=weights)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    print(input_details)\n",
        "    print(output_details)\n",
        "# otherwise load standard tensorflow saved model\n",
        "else:\n",
        "    saved_model_loaded = tf.saved_model.load(weights, tags=[tag_constants.SERVING])\n",
        "    infer = saved_model_loaded.signatures['serving_default']\n",
        "\n",
        "# begin video capture\n",
        "try:\n",
        "    vid = cv2.VideoCapture(int(video_path))\n",
        "except:\n",
        "    vid = cv2.VideoCapture(video_path)\n",
        "\n",
        "out = None\n",
        "\n",
        "# get video ready to save locally if flag is set\n",
        "if output:\n",
        "    # by default VideoCapture returns float instead of int\n",
        "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(vid.get(cv2.CAP_PROP_FPS))\n",
        "    codec = cv2.VideoWriter_fourcc(*output_format)\n",
        "    out = cv2.VideoWriter(output, codec, fps, (width, height))\n",
        "    \n",
        "session.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMqjjSgOuy6Z"
      },
      "source": [
        "## Vari√°veis para coletar os dados desejados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSBams0fuwWE"
      },
      "source": [
        "frame_num = 0 # n√∫mero do frame\n",
        "count_person = 0 # n√∫mero de pedestres contados\n",
        "id_track_list = [] # lista dos pedestres detectados\n",
        "check_count = {} # aux para a contagem\n",
        "check_count_aux = {} # aux para a contagem\n",
        "check_count_2 = {} # aux para a contagem\n",
        "check_count_2_aux = {} # aux para a contagem\n",
        "time_person = {} # tempo que atravessou\n",
        "time_person_aux = {} # aux para calcular o tempo que atravessou\n",
        "x_person_inicial = {} # coordenadas inicias\n",
        "y_person_inicial = {} # coordenadas inicias\n",
        "x_person_final = {} # coordenadas finais\n",
        "y_person_final = {} # coordenadas finais\n",
        "\n",
        "\n",
        "id_track_list_2 = [] # lista de rastreamento de outros objetos (carros,...)\n",
        "inicio_linha1 = {}\n",
        "inicio_linha2 = {}\n",
        "final_linha1 = {}\n",
        "final_linha2 = {}\n",
        "\n",
        "# similar ao pedestre\n",
        "count_car = 0\n",
        "check_count_car = {}\n",
        "check_count_car_aux = {}\n",
        "check_count_car_2 = {}\n",
        "check_count_car_2_aux = {}\n",
        "time_car = {}\n",
        "time_car_aux = {}\n",
        "x_car_inicial = {}\n",
        "y_car_inicial = {}\n",
        "x_car_final = {}\n",
        "y_car_final = {}\n",
        "\n",
        "car_class = {} # classe do veic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8EQsbl_rXoE"
      },
      "source": [
        "class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
        "\n",
        "# by default allow all classes in .names file\n",
        "allowed_classes = list(class_names.values())\n",
        "allowed_classes # classes de detec√ß√£o suportadas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flBxhtGAT7oR"
      },
      "source": [
        "## Detec√ß√£o no v√≠deo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZBjmMbkGs0D"
      },
      "source": [
        "# Fonte: https://github.com/theAIGuysCode/yolov4-deepsort\n",
        "cont = tqdm(total = int(vid.get(cv2.CAP_PROP_FRAME_COUNT)), position=0, leave=True)\n",
        "cont.set_description(\"Frames\")\n",
        "# while video is running\n",
        "while True:\n",
        "    return_value, frame = vid.read()\n",
        "    if return_value:\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(frame)\n",
        "    else:\n",
        "        #print('Video has ended or failed, try a different video format!')\n",
        "        break\n",
        "    frame_num +=1\n",
        "    #print('Frame #: ', frame_num)\n",
        "    #print('Segundos: ', frame_num/int(vid.get(cv2.CAP_PROP_FPS)))\n",
        "    frame_size = frame.shape[:2]\n",
        "    image_data = cv2.resize(frame, (input_size, input_size))\n",
        "    image_data = image_data / 255.\n",
        "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # run detections on tflite if flag is set\n",
        "    if framework == 'tflite':\n",
        "        interpreter.set_tensor(input_details[0]['index'], image_data)\n",
        "        interpreter.invoke()\n",
        "        pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
        "        # run detections using yolov3 if flag is set\n",
        "        if model == 'yolov3' and tiny == True:\n",
        "            boxes, pred_conf = filter_boxes(pred[1], pred[0], score_threshold=0.25,\n",
        "                                            input_shape=tf.constant([input_size, input_size]))\n",
        "        else:\n",
        "            boxes, pred_conf = filter_boxes(pred[0], pred[1], score_threshold=0.25,\n",
        "                                            input_shape=tf.constant([input_size, input_size]))\n",
        "    else:\n",
        "        batch_data = tf.constant(image_data)\n",
        "        pred_bbox = infer(batch_data)\n",
        "        for key, value in pred_bbox.items():\n",
        "            boxes = value[:, :, 0:4]\n",
        "            pred_conf = value[:, :, 4:]\n",
        "\n",
        "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
        "        boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
        "        scores=tf.reshape(\n",
        "            pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
        "        max_output_size_per_class=50,\n",
        "        max_total_size=50,\n",
        "        iou_threshold=iou,\n",
        "        score_threshold=score\n",
        "    )\n",
        "\n",
        "    # convert data to numpy arrays and slice out unused elements\n",
        "    num_objects = valid_detections.numpy()[0]\n",
        "    bboxes = boxes.numpy()[0]\n",
        "    bboxes = bboxes[0:int(num_objects)]\n",
        "    scores = scores.numpy()[0]\n",
        "    scores = scores[0:int(num_objects)]\n",
        "    classes = classes.numpy()[0]\n",
        "    classes = classes[0:int(num_objects)]\n",
        "\n",
        "    # format bounding boxes from normalized ymin, xmin, ymax, xmax ---> xmin, ymin, width, height\n",
        "    original_h, original_w, _ = frame.shape\n",
        "    bboxes = utils.format_boxes(bboxes, original_h, original_w)\n",
        "\n",
        "    # store all predictions in one parameter for simplicity when calling functions\n",
        "    pred_bbox = [bboxes, scores, classes, num_objects]\n",
        "\n",
        "    # read in all class names from config\n",
        "    class_names = utils.read_class_names(cfg.YOLO.CLASSES)\n",
        "\n",
        "    # by default allow all classes in .names file\n",
        "    allowed_classes = list(class_names.values())\n",
        "    \n",
        "    # custom allowed classes \n",
        "    allowed_classes = ['person','car','motorbike','bicycle','bus','truck']\n",
        "\n",
        "    # loop through objects and use class index to get class name, allow only classes in allowed_classes list\n",
        "    names = []\n",
        "    deleted_indx = []\n",
        "    for i in range(num_objects):\n",
        "        class_indx = int(classes[i])\n",
        "        class_name = class_names[class_indx]\n",
        "        if class_name not in allowed_classes:\n",
        "            deleted_indx.append(i)\n",
        "        else:\n",
        "            names.append(class_name)\n",
        "    names = np.array(names)\n",
        "    count = len(names)\n",
        "\n",
        "    # delete detections that are not in allowed_classes\n",
        "    bboxes = np.delete(bboxes, deleted_indx, axis=0)\n",
        "    scores = np.delete(scores, deleted_indx, axis=0)\n",
        "\n",
        "    # encode yolo detections and feed to tracker\n",
        "    features = encoder(frame, bboxes)\n",
        "    detections = [Detection(bbox, score, class_name, feature) for bbox, score, class_name, feature in zip(bboxes, scores, names, features)]\n",
        "\n",
        "    #initialize color map\n",
        "    cmap = plt.get_cmap('tab20b')\n",
        "    colors = [cmap(i)[:3] for i in np.linspace(0, 1, 20)]\n",
        "\n",
        "    # run non-maxima supression\n",
        "    boxs = np.array([d.tlwh for d in detections])\n",
        "    scores = np.array([d.confidence for d in detections])\n",
        "    classes = np.array([d.class_name for d in detections])\n",
        "    indices = preprocessing.non_max_suppression(boxs, classes, nms_max_overlap, scores)\n",
        "    detections = [detections[i] for i in indices]       \n",
        "\n",
        "    # Call the tracker\n",
        "    tracker.predict()\n",
        "    tracker.update(detections)\n",
        "\n",
        "    # update tracks\n",
        "    for track in tracker.tracks:\n",
        "        if not track.is_confirmed() or track.time_since_update > 1:\n",
        "            continue \n",
        "        bbox = track.to_tlbr()\n",
        "        class_name = track.get_class()\n",
        "        \n",
        "    # draw bbox on screen\n",
        "        color = colors[int(track.track_id) % len(colors)]\n",
        "        color = [i * 255 for i in color]\n",
        "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), color, 2)\n",
        "        cv2.rectangle(frame, (int(bbox[0]), int(bbox[1]-30)), (int(bbox[0])+(len(class_name)+len(str(track.track_id)))*17, int(bbox[1])), color, -1)\n",
        "        cv2.putText(frame, class_name + \"-\" + str(track.track_id),(int(bbox[0]), int(bbox[1]-10)),0, 0.75, (255,255,255),2)\n",
        "\n",
        "        #if dominio(centroid_box(bbox),conflict_area[0]):\n",
        "        check_count[str(track.track_id)] = str(passou_da_linha(centroid_box(bbox),conflict_area[0]))\n",
        "        #ja tava comentado check_count[str(track.track_id)] = str(passou_da_linha_reta_horizontal(centroid_box(bbox),linha[1]))\n",
        "\n",
        "        #if dominio(centroid_box(bbox),conflict_area[2]):\n",
        "        check_count_2[str(track.track_id)] = str(passou_da_linha(centroid_box(bbox),conflict_area[2]))\n",
        "\n",
        "        # Objeto dentro da √°rea de interesse\n",
        "        if dominio(centroid_box(bbox),conflict_area[1]):\n",
        "            check_count_car[str(track.track_id)] = str(passou_da_linha(centroid_box(bbox),conflict_area[1]))\n",
        "\n",
        "        if dominio(centroid_box(bbox),conflict_area[3]):\n",
        "            check_count_car_2[str(track.track_id)] = str(passou_da_linha(centroid_box(bbox),conflict_area[3]))\n",
        "\n",
        "        try: # Bloco do pedestres. A ideia √© salvar o momento que o pedestre aparece no v√≠deo e verificar o momento que ele atravessa\n",
        "            if (class_name == 'person') & (str(track.track_id) not in id_track_list): \n",
        "                inicio_linha1[str(track.track_id)] = check_count[str(track.track_id)]\n",
        "                inicio_linha2[str(track.track_id)] = check_count_2[str(track.track_id)]\n",
        "                #count_person += 1\n",
        "                id_track_list.append(str(track.track_id))\n",
        "                id_track_list = list(set(id_track_list))\n",
        "                time_person_aux[str(track.track_id)] = frame_num\n",
        "                x_person_inicial[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_person_inicial[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            #if (class_name == 'person') & (str(track.track_id) not in id_track_list): \n",
        "            #    count_person += 1\n",
        "            #    id_track_list.append(str(track.track_id))\n",
        "            #    id_track_list = list(set(id_track_list))\n",
        "            #    time_person_aux[str(track.track_id)] = frame_num\n",
        "            #    x_person_inicial[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "            #    y_person_inicial[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            if (class_name == 'person') & (str(track.track_id) in id_track_list) & (check_count_2[str(track.track_id)] != check_count_2_aux[str(track.track_id)]) & (str(track.track_id) not in id_track_list_2):\n",
        "                time_person[str(track.track_id)] = frame_num - time_person_aux[str(track.track_id)]\n",
        "                id_track_list_2.append(str(track.track_id))\n",
        "                id_track_list_2 = list(set(id_track_list_2))\n",
        "                final_linha1[str(track.track_id)] = check_count[str(track.track_id)]\n",
        "                final_linha2[str(track.track_id)] = check_count_2[str(track.track_id)]\n",
        "                count_person += 1\n",
        "                x_person_final[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_person_final[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            if (class_name == 'person') & (str(track.track_id) in id_track_list) & (check_count[str(track.track_id)] != check_count_aux[str(track.track_id)]) & (str(track.track_id) not in id_track_list_2):\n",
        "                time_person[str(track.track_id)] = frame_num - time_person_aux[str(track.track_id)]\n",
        "                id_track_list_2.append(str(track.track_id))\n",
        "                id_track_list_2 = list(set(id_track_list_2))\n",
        "                final_linha1[str(track.track_id)] = check_count[str(track.track_id)]\n",
        "                final_linha2[str(track.track_id)] = check_count_2[str(track.track_id)]\n",
        "                count_person += 1\n",
        "                x_person_final[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_person_final[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            #print(check_count[str(track.track_id)])\n",
        "            #print(check_count_aux[str(track.track_id)])\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "\n",
        "        try: # Bloco dos ve√≠culos, similar ao pedestre\n",
        "            if (class_name != 'person') & (str(track.track_id) not in id_track_list) & (check_count_car[str(track.track_id)] != check_count_car_aux[str(track.track_id)]): \n",
        "                count_car += 1\n",
        "                id_track_list.append(str(track.track_id))\n",
        "                id_track_list = list(set(id_track_list))\n",
        "                time_car_aux[str(track.track_id)] = frame_num\n",
        "                car_class[str(track.track_id)] = class_name\n",
        "                x_car_inicial[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_car_inicial[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            if (class_name != 'person') & (str(track.track_id) not in id_track_list) & (check_count_car_2[str(track.track_id)] != check_count_car_2_aux[str(track.track_id)]): \n",
        "                count_car += 1\n",
        "                id_track_list.append(str(track.track_id))\n",
        "                id_track_list = list(set(id_track_list))\n",
        "                time_car_aux[str(track.track_id)] = frame_num\n",
        "                car_class[str(track.track_id)] = class_name\n",
        "                x_car_inicial[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_car_inicial[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            if (class_name != 'person') & (str(track.track_id) in id_track_list) & (check_count_car_2[str(track.track_id)] != check_count_car_2_aux[str(track.track_id)]) & (time_car_aux[str(track.track_id)] != frame_num):\n",
        "                time_car[str(track.track_id)] = frame_num - time_car_aux[str(track.track_id)]\n",
        "                x_car_final[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_car_final[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "            if (class_name != 'person') & (str(track.track_id) in id_track_list) & (check_count_car[str(track.track_id)] != check_count_car_aux[str(track.track_id)]) & (time_car_aux[str(track.track_id)] != frame_num):\n",
        "                time_car[str(track.track_id)] = frame_num - time_car_aux[str(track.track_id)]\n",
        "                x_car_final[str(track.track_id)] = centroid_box(bbox)[0]\n",
        "                y_car_final[str(track.track_id)] = centroid_box(bbox)[1]\n",
        "\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        \n",
        "\n",
        "    \n",
        "    # if enable info flag then print details about each track\n",
        "    #    if info:\n",
        "            #print(\"Tracker ID: {}, Class: {},  BBox Coords (xmin, ymin, xmax, ymax): {}\".format(str(track.track_id), class_name, (int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3]))))\n",
        "    \n",
        "    \n",
        "    cv2.line(frame,(conflict_area[0][0],conflict_area[0][1]),(conflict_area[0][2],conflict_area[0][3]),(255,0,0),5) \n",
        "    cv2.line(frame,(conflict_area[1][0],conflict_area[1][1]),(conflict_area[1][2],conflict_area[1][3]),(255,0,0),5) \n",
        "    cv2.line(frame,(conflict_area[2][0],conflict_area[2][1]),(conflict_area[2][2],conflict_area[2][3]),(255,0,0),5) \n",
        "    cv2.line(frame,(conflict_area[3][0],conflict_area[3][1]),(conflict_area[3][2],conflict_area[3][3]),(255,0,0),5) \n",
        "\n",
        "    cv2.putText(frame, \"Contador de pessoas: {}\".format(count_person), (5, 35), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, \"Contador de veiculos: {}\".format(count_car), (5, 70), cv2.FONT_HERSHEY_COMPLEX_SMALL, 2, (0, 255, 0), 2)\n",
        "    # calculate frames per second of running detections\n",
        "    #fps = 1.0 / (time.time() - start_time)\n",
        "    #print(\"FPS: %.2f\" % fps)\n",
        "\n",
        "    result = np.asarray(frame)\n",
        "    result = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    #Progresso\n",
        "    cont.update(1)\n",
        "    \n",
        "    \n",
        "    # if output flag is set, save video file\n",
        "    if saida:\n",
        "        out.write(result)\n",
        "\n",
        "\n",
        "    check_count_aux = check_count.copy()\n",
        "    check_count_2_aux = check_count_2.copy()\n",
        "    \n",
        "    check_count_car_aux = check_count_car.copy()\n",
        "    check_count_car_2_aux = check_count_car_2.copy()\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "\n",
        "print(\"Veiculos: %.2f\" %  int(count_car))\n",
        "print(\"Pedestres: %.2f\" %  int(count_person))\n",
        "\n",
        "print(\"Video in FPS: %.2f\" %  int(vid.get(cv2.CAP_PROP_FPS)))\n",
        "print(\"Video in n frames: %.2f\" %  int(vid.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "print(\"Video in duration: %.2f\" %  ((vid.get(cv2.CAP_PROP_FRAME_COUNT))/(vid.get(cv2.CAP_PROP_FPS))))\n",
        "\n",
        "real_fps = frame_num / ((vid.get(cv2.CAP_PROP_FRAME_COUNT))/(vid.get(cv2.CAP_PROP_FPS)))\n",
        "#out = cv2.VideoCapture(output)\n",
        "#out.set(cv2.CAP_PROP_FPS, real_fps)\n",
        "\n",
        "#print(\"Video real FPS: %.2f\" %  int(real_fps))\n",
        "#print(\"Video out FPS: %.2f\" %  int(out.get(cv2.CAP_PROP_FPS)))\n",
        "#print(\"Video out n frames: %.2f\" %  int(out.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "#print(\"Video out duration: %.2f\" %  ((out.get(cv2.CAP_PROP_FRAME_COUNT))/(out.get(cv2.CAP_PROP_FPS))))\n",
        "#print(time.time())\n",
        "\n",
        "time_start = time_person_aux\n",
        "time_real = time_person\n",
        "\n",
        "x_inicial = x_person_inicial\n",
        "x_final = x_person_final\n",
        "y_inicial = y_person_inicial\n",
        "y_final = y_person_final\n",
        "\n",
        "relatorio = pd.DataFrame(\n",
        "    {\n",
        "        'time_start': time_start,\n",
        "        'time': time_real,\n",
        "        'inicio_linha_1':inicio_linha1,\n",
        "        'inicio_linha_2':inicio_linha2,\n",
        "        'final_linha_1':final_linha1,\n",
        "        'final_linha_2':final_linha2,\n",
        "        'x_inicial': x_inicial,\n",
        "        'y_inicial': y_inicial,\n",
        "        'x_final': x_final,\n",
        "        'y_final': y_final\n",
        "    }\n",
        ")\n",
        "relatorio.to_csv(\"./outputs/\"+ nome_arquivo_video +\"/out.csv\") # salvar os dados finais dos ped\n",
        "\n",
        "\n",
        "time_start = time_car_aux\n",
        "time_real = time_car\n",
        "\n",
        "x_inicial = x_car_inicial\n",
        "x_final = x_car_final\n",
        "y_inicial = y_car_inicial\n",
        "y_final = y_car_final\n",
        "\n",
        "relatorio_2 = pd.DataFrame(\n",
        "    {\n",
        "        'time_start': time_start,\n",
        "        'time': time_real,\n",
        "        'classe': car_class,\n",
        "        'inicio_linha_1':inicio_linha1,\n",
        "        'inicio_linha_2':inicio_linha2,\n",
        "        'final_linha_1':final_linha1,\n",
        "        'final_linha_2':final_linha2,\n",
        "        'x_inicial': x_inicial,\n",
        "        'y_inicial': y_inicial,\n",
        "        'x_final': x_final,\n",
        "        'y_final': y_final\n",
        "    }\n",
        ")\n",
        "relatorio_2.to_csv(\"./outputs/\"+ nome_arquivo_video +\"/out_car.csv\") # salvar os dados finais dos veic\n",
        "\n",
        "\n",
        "cont.close()\n",
        "if False:\n",
        "    vid = cv2.VideoCapture(output)\n",
        "\n",
        "    width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = real_fps\n",
        "    codec = cv2.VideoWriter_fourcc(*output_format)\n",
        "    out_put_path = output\n",
        "    out2 = cv2.VideoWriter(out_put_path[:-4]+'_real_fps'+out_put_path[-4:], codec, fps, (width, height))\n",
        "\n",
        "\n",
        "    while True:\n",
        "        return_value, frame = vid.read()\n",
        "        if return_value:\n",
        "            frame = frame\n",
        "        else:\n",
        "            print('Video has ended or failed, try a different video format!')\n",
        "            break\n",
        "                # if output flag is set, save video file\n",
        "        \n",
        "        out2.write(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'): break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmeeLEXYUmTF"
      },
      "source": [
        "# Salvar csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR0PWbi1ayAB"
      },
      "source": [
        "fps = cv2.VideoCapture(output).get(cv2.CAP_PROP_FPS)\n",
        "dados = pd.read_csv(\"./outputs/\"+ nome_arquivo_video +\"/out.csv\")\n",
        "dados_car = pd.read_csv(\"./outputs/\"+ nome_arquivo_video +\"/out_car.csv\")\n",
        "dados_car.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3XOTY8VIQh5"
      },
      "source": [
        "dados.columns = ['id','time_start','time','inicio_linha_1', \t'inicio_linha_2', \t'final_linha_1', \t'final_linha_2','x_inicial',\t'y_inicial',\t'x_final',\t'y_final']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VlW9QxjfpOC"
      },
      "source": [
        "dados['time_start'] = dados['time_start'] / fps\n",
        "dados['time'] = dados['time'] / fps\n",
        "\n",
        "dados_car['time_start'] = dados_car['time_start'] / fps\n",
        "dados_car['time'] = dados_car['time'] / fps\n",
        "\n",
        "dados_completos = dados.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EadrFXwiQc1q"
      },
      "source": [
        "dados_completos.to_csv(\"./outputs/\"+ nome_arquivo_video +\"/atrasos.csv\")\n",
        "dados_car.to_csv(\"./outputs/\"+ nome_arquivo_video +\"/carros.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}